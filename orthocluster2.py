#!/usr/bin/python

'''
This script can be used to calculate how many identified Dmel
orthologs in other genomes are clustered in the same group 
as their Dmel ortholog, and how their motif compositions differ.
It requires clustering results from cluster.py and the orthologs csv
file resulting from recblast.py.
Author: Barbara Vreede
Contact: b.vreede@gmail.com
Date: 17 March 2015
'''

import csv,itertools,re,random
from jellyfish import levenshtein_distance as jld
from collections import Counter
import pylab as pl
import numpy as np
import config



#CUSTOMIZE INPUT AND OUTPUT FILES
allspp = ['dmel','tcas','dpul','smar','isca','turt']
dbfolder = "/home/barbara/Dropbox/shared_work/zinc_finger_data/data"
orthfolder = "%s/results/orthologs" %dbfolder

clusterfile = "results/clustering-string_all2-average.csv" #candidate for ditching
orthologli = [orthfolder + "/%s-orthologs.csv" %spp for spp in allspp]

seqvsseq = "%s/dmeltoother.csv" %orthfolder #candidate for ditching.
resultsummary = "%s/orthocomp_summary.csv" %orthfolder

#list with motifs in their actual frequency; generated by findmotif.py
allmotifs = "databases/allmotifs.txt"

hmimage = "images/ortholog_combinations.svg"
motifseq = "results/150111-SM00355-all2_seq_motifseq.fasta"
motifaaseq = "sequences/allmotifs.fasta"




#END CUSTOMIZATION

'''
Prep variables and lists to store results, open resultfiles
'''
seqcomp = open(seqvsseq, "w")
ressum = open(resultsummary, "w")
ressum.write('sp1,sp2,ortholog_avgdist,std,random_avgdist,std,n_orthologs,n_identical,n_ident-random\n')

m2m,letters = [],[] #lists to collect combinations of letters (orthologs where two different domain classes are found in the same location) and the total appearance of those letters, respectively. 

#TAKE THIS FROM FINDMOTIF.PY: the alphabet and corresponding motiflist, and the length of plink/alink
plink,alink = 0,0
motiflist = ['2_7_4','2_8_3','2_9_3','2_10_5','2_11_3','2_11_4','2_12_2','2_12_3','2_12_4','2_12_5','2_12_6','2_13_3',
'2_13_4','2_14_3','2_14_4','2_15_4','3_8_3','4_12_3','4_12_4','4_15_3']
alphabet = """ABCDEFGHIJKLMNPQRSTUVWXYabcdefghijklmnopqrstuvwxy1234567890!@%^&*()_-+={}[]:;"'|\<,>.?/~`ABCDEFGHIJKLMNPQRSTUVWXYabcdefghijklmnopqrstuvwxy1234567890!@%^&*()_-+={}[]:;"'|\<,>.?/~`"""
translationdict = {motif: alphabet[a] for a,motif in enumerate(motiflist)} # dictionary of motifs and the corresponding string element
translationreverse = {translationdict[m]: m for m in motiflist}

orthocombos = [] #list where combinations of matching orthologs will be stored
conservation,conserv_rand = {},{} #dictionary where lists of conservation per side are stored per motif, and same for random comparisons
for m in motiflist:
	mlen = sum([int(mi) for mi in m.split('_')]) + plink + alink + 5
	mli = [0 for n in range(mlen)] #a 0 for each site, and finally a 0 that will count how many times this motif was found conserved
	conservation[m] = list(mli)
	conserv_rand[m] = list(mli)

'''
Prep libraries from existing result files
'''
#dictionary with the motifstructure of each gene
mseq_fa = open("%s/%s" %(dbfolder,motifseq))
mseq_dx = {}
seq_value = ''
for line in mseq_fa:
	if line[0] == ">":
		try:
			mseq_dx[key] = seq_value
			seq_value = ''
		except NameError:
			pass
		key = line[1:].strip()
	else:
		seq_value += line.strip()
mseq_dx[key] = seq_value

#dictionary with the aminoacid sequence of each motif hit
mhit_fa = open("%s/%s" %(dbfolder,motifaaseq))
mhit_dx = {}

#dictionary with lists of motif sequences, ordered per motif
mhit_rand_dx = {}
for a in alphabet:
	mhit_rand_dx[a] = [] #add empty lists for each possible motif identifier

seq_value = ''
for line in mhit_fa:
	if line[0] == ">":
		try:
			mhit_dx[key] = seq_value
			mhit_rand_dx[m_ran] = mhit_rand_dx[m_ran] + [seq_value]
			seq_value = ''
		except NameError:
			pass
		key = line[1:].strip()
		m_ran = line.strip().split('|')[-1].split('-')[0]
	else:
		seq_value += line.strip()
mhit_dx[key] = seq_value
mhit_rand_dx[m_ran] = mhit_rand_dx[m_ran] + [seq_value]

#random list of motifs for frequency-dependent selection of motifs
allmotxt = open("%s/%s" %(dbfolder,allmotifs))
allmotli = []
for m in allmotxt:
	allmotli.append(m.strip())
backupmotli = list(allmotli) #in case the list needs to be generated again. To prevent backupmotli from undergoing the same modifications as allmotli, it's imported as a new list entirely.
random.shuffle(allmotli)

def orthos(gene,k,ol):
	'''
	Look up per gene what their ortholog is. NB this may be multiple, as the gene could have multiple isoforms.
	'''
	isoforms = [ol[0][i] for i,j in enumerate(ol[k]) if j == gene]
	return isoforms #list of all isoforms
 
def clusters(genes,cdict): #genes is a list
	'''
	Look up the cluster they are assigned (both the Dmel and the Spp gene)
	'''
	clusters = [cdict[g.split('|')[2]] for g in genes]
	return clusters #list of clusters, same order as genes


def simple_wordcomp(i,j):
	'''
	Calculate pairwise distances for all the strings collected. As strings
	are regular expressions, first expand the re. and then calculate all distances
	pairwise. Return the minimal distance (with and without spaces).
	'''
	# translate strings[i] and strings[j] to all possible expressions
	sisplit = [part.split('|') for part in re.split(r'\{(.*?)\}',i)]
	sjsplit = [part.split('|') for part in re.split(r'\{(.*?)\}',j)]
	si,sj = [],[]
	for x in itertools.product(*sisplit):
		si.append(''.join(x))
	for x in itertools.product(*sjsplit):
		sj.append(''.join(x))
	# check jld of all strings[i] options against all strings[j] options
	distance = []
	for sin in si:
		for sjn in sj:
			distance.append(jld(sin,sjn))
	# return the minimum distance
	return min(distance)

def complex_wordcomp(i,j):
	'''
	Calculate pairwise distances for all the strings collected. As strings
	are regular expressions, first expand the re. and then calculate all distances
	pairwise. Return the minimal distance (with and without spaces).
	Additionally: find out which domain classes 'replace' each other in orthologs.
	Save these results in global lists.
	'''
	global m2m
	global letters
	# translate strings[i] and strings[j] to all possible expressions
	sisplit = [part.split('|') for part in re.split(r'\{(.*?)\}',i)]
	sjsplit = [part.split('|') for part in re.split(r'\{(.*?)\}',j)]
	si,sj = [],[]
	for x in itertools.product(*sisplit):
		si.append(''.join(x))
	for x in itertools.product(*sjsplit):
		sj.append(''.join(x))
	# check jld of all strings[i] options against all strings[j] options
	distance,distance2,sequencecomp = [],[],[]
	for sin in si:
		for sjn in sj:
			distance.append(jld(sin,sjn))
			#remove Zs and do it again
			sin = sin.replace('Z','')
			sjn = sjn.replace('Z','')
			distance2.append(jld(sin,sjn))
			sequencecomp.append("%s,%s" %(sin,sjn))
	# if there are differences: which motif turned into which?
	if min(distance2) > 0: #use the sequences without space/Z
		for k,d in enumerate(distance2):
			if d == min(distance2):
				#distance2 and sequencecomp have the same order, so sequencecomp[k] has sequences corresponding to distance = d
				comps = sequencecomp[k].split(',')
				sik,sjk = comps[0],comps[1]
				if len(sik) == len(sjk):
					for ki,si in enumerate(sik):
						letters.append(sjk[ki])
						letters.append(si)
						if si != sjk[ki]:
							fs = frozenset([si,sjk[ki]])
							m2m.append(fs)
					seqcomp.write("%s,%s\n" %(sik,sjk))
	# return the minimum distance
	return min(distance),min(distance2)

def calcdistance(gene,corths,ranseq):
	'''
	Calculate the minimum distance between the gene and its orthologs
	where distances are calculated between strings that summarize protein
	architecture.
	'''
	dists,dists_ran = [],[]
	seq_g = mseq_dx[gene]
	for co in corths:
		seq_c = mseq_dx[co]
		dist = simple_wordcomp(seq_g,seq_c)
		dist_r = simple_wordcomp(ranseq,seq_c)
		dists.append(dist)
		dists_ran.append(dist_r)
	return min(dists),min(dists_ran)

def randomorth(gene):
	'''
	Generate a random motif sequence based on identical ZF structure
	(including conservation of spacing) but with random frequency-dependent
	sampling of motifs.
	'''
	global allmotli
	regex = ['{', '|'] #components of regular expressions, to be excluded
	# NB } is not used because it indicates the re itself, and thus needs to be substituted by an element, too
	rehit = 0
	seq_g = mseq_dx[gene]
	ranseq = ""
	for l in seq_g:
		if l == 'Z':
			ranseq += 'Z'
		elif l in regex: #regex component followed by a motif
			rehit = 1
		elif rehit == 1: #catches the motif following the regex indicator
			rehit = 0
		else:
			try:
				ranseq += allmotli.pop(0) #remove the first element from the list and use it in a random seq
			except IndexError: #list is empty, so refill it.
				allmotli = list(backupmotli)
				random.shuffle(allmotli)
				ranseq += allmotli.pop(0)
	return ranseq

def list_re(seq,keepz="no"):
	'''
	Removes spaces ('Z') and returns the sequence in list
	format for easy comparison, pooling regex elements.
	'''
	if keepz == "no":
		seq = seq.replace('Z','')
	seqli = []
	flag = 0 # used to mark regular expression
	regex = ''
	for s in seq:
		if s == '{':
			regex += s
			flag = 1
		elif s == '}':
			regex += s
			seqli.append(regex)
			regex = ''
			flag = 0
		elif flag == 1:
			regex += s
		else:
			seqli.append(s)
	return seqli


def plotbars(data1,data2,sp1,sp2):
	pl.figure()
	nrbins1 = max(data1)
	nrbins2 = max(data2)
	pl.hist(data1, bins=nrbins1, histtype='stepfilled', normed=True, color='c', alpha=0.8, label='Orthologs')
	pl.hist(data2, bins=nrbins2, histtype='stepfilled', normed=True, color='r', alpha=0.4, label='Random')
	pl.xlabel("Levenshtein distance")
	pl.ylabel("Proportion")
	if sp1 == "total":
		pl.legend()
	pl.savefig("%s/histograms/%s-%s_Levensh-distr.png" %(orthfolder,sp1,sp2))
	pl.clf()
	pl.close("all")

def regexrem(el):
	'''
	remove regex components
	'''
	el = el.replace('{','')
	el = el.replace('}','')
	el = el.replace('|','')
	return el

def mchecker(el,mcheck):
	'''
	Updates the list 'mcheck' that contains all motifs that have been
	passed so far in the protein. Using a count function, mcheck can
	later be used to determine the rank of the latest motif.
	'''
	el = regexrem(el)
	#add each element independently
	for e in el:
		mcheck.append(e)
	return mcheck

def aacomp_det(aa1,aa2,li):
	'''
	Function for the detailed comparison of two aminoacid sequences
	(called within aacomp).
	'''
	#for each element in aa1:
	for n,el1 in enumerate(aa1):
		el2 = aa2[n]
		if el1 != el2: #compare with the corresponding letter in aa2
			li[n] += 1 #adjust the list with +1 if it is different, and not if it is not different
	li[-1] += 1 #update the final element in the list with +1
	return li


def aacomp(gene1,m1,gene2,m2):
	'''
	Function that compares the aminoacid sequences of homologous
	motifs to identify conserved aminoacids.
	'''
	#compile gene names
	g1 = gene1 + '|' + m1 
	g2 = gene2 + '|' + m2
	m = m1[0] #the motif identifier
	#get the random sequence
	mrandomlist = mhit_rand_dx[m] #from the orthologs: all orths
	rand_n = random.randint(0,len(mrandomlist)-1)
	s_r = mrandomlist[rand_n]
	#collect sequences to be compared
	s1 = mhit_dx[g1]
	s2 = mhit_dx[g2]

	#motif name, and get the global dictionary for motif lists
	motname = translationreverse[m]
	global conservation
	global conserv_rand
	
	#now run comparisons
	### PART 1: compare gene1 + gene 2
	li_mot = conservation[motname]
	limot_updated = aacomp_det(s1,s2,li_mot)
	conservation[motname] = limot_updated #update global dictionary with limot_updated

	### PART 2: compare either gene 1 or gene 2, and random
	#pick gene 1 or 2
	if random.randint(1,2) == 1:
		s_g = s1
	else:
		s_g = s2
	li_mot_ran = conserv_rand[motname]
	limot_updated_ran = aacomp_det(s_g,s_r,li_mot_ran)
	conserv_rand[motname] = limot_updated_ran #update global dictionary with limot_updated
	
def makeheatmap(table,name,xlab,ylab):
	'''
	Use 2D data (list of lists) to generate a heatmap of the data.
	'''
	#pl.figure()
	data = pl.array(table)
	colourformap = "YlOrBr"
	fig,ax = pl.subplots()
	heatmap = pl.pcolor(data, cmap=colourformap,vmin=0,vmax=0.25)
	cbar = pl.colorbar(heatmap)
	
	# put the major ticks at the middle of each cell
	ax.set_xticks(np.arange(data.shape[1]) + 0.5, minor=False)
	ax.set_yticks(np.arange(data.shape[0]) + 0.5, minor=False)
	pl.axis('tight') #remove the white bar
	ax.invert_yaxis() #make sure it starts counting from the top
		
	#make the labels
	ax.set_xticklabels(xlab, minor=False, rotation=90)
	ax.set_yticklabels(ylab, minor=False)
		
	# save the figure
	pl.savefig("%s/heatmaps/%s.png" %(orthfolder,name), dpi = 300)
	pl.savefig("%s/heatmaps/%s.svg" %(orthfolder,name), dpi = 300)
	pl.clf()
	pl.close("all")
	

'''
Process the data in each ortholog comparison file.
'''
alldists,alldists_ran = [],[]
for orthfile in orthologli:
	try:
		of = csv.reader(open(orthfile))
	except IOError:
		continue
	ol1 = [line for line in of] # list from the file
	ol2 = [[x[i] for x in ol1] for i in range(len(ol1[0]))] # transpose the list
	### for each combination of species,
	sp1 = ol2[0][0] #the first column (now row) contains the comparison species
	for n in range(1,len(ol2)): #for each species comparison
		sp2 = ol2[n][0]
		print "Comparing orthologs between " + sp1 + " and " + sp2 + "..."
		#make a list of all the unique orthologs per species
		allorth = list(set(ol2[n][1:]))
		allorth.remove('')
		orthototal = len(allorth) #total no. of orthologs for this species combination
		dists,dists_ran = [],[]
		#collect the data
		for gene in allorth:
			corths = orthos(gene,n,ol2) #collect all sp1 isoforms that are mentioned as orthologs for this gene
			orthocombos.append([gene,corths])
			ranseq = randomorth(gene)
			di,di_r = calcdistance(gene,corths,ranseq)
			dists.append(di)
			dists_ran.append(di_r)
		#make plot of distance distributions
		plotbars(dists,dists_ran,sp1,sp2)
		#calculate mean, stdev, no. identical orthologs; respectively (for data and random model)
		arrdi = np.array(dists) #make array for numpy analysis...
		arrdi_ran = np.array(dists_ran)
		amean = np.mean(arrdi)
		amean_r = np.mean(arrdi_ran)
		astdv = np.std(arrdi)
		astdv_r = np.std(arrdi_ran)
		#following commented out, but can be used to find the mode/most common distance
		'''
		data = Counter(dists)
		dmode = data.most_common(1)
		data_ran = Counter(dists_ran)
		dmode_r = data_ran.most_common(1)
		'''
		# identical orthologs, so distance = 0:
		idcount = dists.count(0)
		idcount_r = dists_ran.count(0)
		ressum.write('%s,%s,%s,%s,%s,%s,%s,%s,%s\n' %(sp1,sp2,amean,astdv,amean_r,astdv_r,orthototal,idcount,idcount_r))
		alldists += dists
		alldists_ran += dists_ran
plotbars(alldists,alldists_ran,"total","total")



'''
Part II:
Is conservation of aminoacid sequence rather than spacing responsible
for conservation of motif type?
'''

print "All ortholog comparisons made. Now comparing amino acid sequences..."
## for each item in the ortholog-combo list:
for pair in orthocombos:
	# pick up the motif structure
	seqli_g = list_re(mseq_dx[pair[0]]) #make a list of the elements in this sequence, no spaces
	for o in pair[1]:
		seqli_o = list_re(mseq_dx[o])
		# should we do a simple_wordcomp with a max levenshtein distance for the length here?
		if len(seqli_o) == len(seqli_g): #lists contain the same number of elements, so side-by-side comparisons are possibly warranted...
			# but only run the side-by-side comparison if they are below a similarity threshold.
			testdis = simple_wordcomp(mseq_dx[o],mseq_dx[pair[0]])
			mcheck_g,mcheck_o = [],[] # to collect motifs that were investigated, as the sequence of each motif is identified by the order in the protein.
			for n in range(len(seqli_o)):
				el_o = seqli_o[n]
				el_g = seqli_g[n]
				#add motifs to mcheck lists so order can be determined
				mcheck_g = mchecker(el_g,mcheck_g)
				mcheck_o = mchecker(el_o,mcheck_o)
				#determine the distance between homologous elements in list
				sdis = simple_wordcomp(el_o,el_g)
				if sdis == 0: #homologous motifs identified
					el_o = regexrem(el_o) #remove regexcomponents
					for l in el_o:
						if l in el_g:
							mlo = l + '-' + str(mcheck_o.count(l) - 1)
							mlg = l + '-' + str(mcheck_g.count(l) - 1)
							aacomp(pair[0],mlg,o,mlo)
				else: #motifs have replaced each other.
					if len(el_o) == 1 and len(el_g) == 1: #neither is ambiguous.
						fs = frozenset([el_o,el_g])
						letters.append(el_o)
						letters.append(el_g)
						m2m.append(fs)

ressum.write("\nHomologous motifs counted:\n")

## make the data for final processing: proportional to number of comparisons, remove the counter
countdx = {} #add a dictionary that keeps the counter separate
for m in motiflist:
	consli = list(conservation[m])
	consli_r = list(conserv_rand[m])
	counter = consli[-1]
	ressum.write("%s,%s\n" %(m,counter))
	countdx[m] = counter
	if counter == 0:
		continue
	consli_new,consli_new_r = [],[]
	for n in range(len(consli)-1):
		c = consli[n]/float(counter)
		consli_new.append(c)
		c_r = consli_r[n]/float(counter)
		consli_new_r.append(c_r)
	conservation[m] = list(consli_new)
	conserv_rand[m] = list(consli_new_r)
	table = [consli_new] + [consli_new_r]
	xlab = []
	ylab = ["orthologous","random"]
	makeheatmap(table,m,xlab,ylab)


'''
Part III:
Which domain classes are parallel in non-identical orthologs?
Make a heatmap of this data.
'''
print "Checking homologous but not identical motifs..."

ressum.write("\nMotif transitions counted:\n,")
for m in motiflist:
	ressum.write("%s," %m)
ressum.write("\n")

combocount = Counter(m2m) #dictionary with frozenset-motifcombinations, and their frequency
letterscount = Counter(letters) #dictionary with individual letters, and their frequency

#collect data for the heatmap in a 2d list
table1,table2 = [],[]
for m1 in motiflist:
	ressum.write("%s," %m1)
	l1 = translationdict[m1] #corresponding string element of main motif
	tot1 = letterscount[l1] #total frequency of this motif in the dataset
	row1,row2 = [],[] #empty rows that will collect relative frequency data
	for m2 in motiflist:
		l2 = translationdict[m2] #corresponding string element of comparing motif
		tot2 = letterscount[l2]
		fs = frozenset([l1,l2]) #combined frozenset of main and comparing motif
		if fs in combocount: #if this combination is found:
			ressum.write("%s," %combocount[fs])
			freq = float(combocount[fs]) #give total frequency of combination (float to enable float result)
		else:
			ressum.write("0,")
			freq = 0
		if tot1 == 0:
			row1.append('0.0')
		else:
			row1.append(freq/tot1)
		if tot1 * tot2 == 0:
			row2.append('0.0')
		else:
			row2.append(freq/(tot1*tot2))
	table1.append(row1)
	table2.append(row2)
	ressum.write("\n")

makeheatmap(table1,"substitutions_norm1",motiflist,motiflist)
makeheatmap(table2,"substitutions_norm2",motiflist,motiflist)

ressum.close()


