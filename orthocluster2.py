#!/usr/bin/python

'''
This script can be used to calculate how many identified Dmel
orthologs in other genomes are clustered in the same group 
as their Dmel ortholog, and how their motif compositions differ.
It requires clustering results from cluster.py and the orthologs csv
file resulting from recblast.py.
Author: Barbara Vreede
Contact: b.vreede@gmail.com
Date: 17 March 2015
'''

import csv,itertools,re,random
from jellyfish import levenshtein_distance as jld
from collections import Counter
import pylab as pl
import numpy as np

#CUSTOMIZE INPUT AND OUTPUT FILES
allspp = ['dmel','tcas','dpul','smar','isca','turt']
dbfolder = "/home/barbara/Dropbox/shared_work/zinc_finger_data/data"
orthfolder = "%s/results/orthologs" %dbfolder

clusterfile = "results/clustering-string_all2-average.csv" #candidate for ditching
orthologli = [orthfolder + "/%s-orthologs.csv" %spp for spp in allspp]

seqvsseq = "%s/dmeltoother.csv" %orthfolder #candidate for ditching.
resultsummary = "%s/orthocomp_summary.csv" %orthfolder

#list with motifs in their actual frequency; generated by findmotif.py
allmotifs = "databases/allmotifs.txt"

hmimage = "images/ortholog_combinations.svg"
motifseq = "results/150111-SM00355-all2_seq_motifseq.fasta"
motifaaseq = "sequences/allmotifs.fasta"




#END CUSTOMIZATION

'''
Prep variables and lists to store results, open resultfiles
'''
seqcomp = open(seqvsseq, "w")
ressum = open(resultsummary, "w")
ressum.write('sp1,sp2,ortholog_avgdist,std,random_avgdist,std,n_orthologs,n_identical,n_ident-random\n')

m2m,letters = [],[] #lists to collect combinations of letters (orthologs where two different domain classes are found in the same location) and the total appearance of those letters, respectively. 

#TAKE THIS FROM FINDMOTIF.PY: the alphabet and corresponding motiflist, and the length of plink/alink
plink,alink = 4,4
motiflist = ['2_7_4','2_8_3','2_9_3','2_10_5','2_11_3','2_11_4','2_12_2','2_12_3','2_12_4','2_12_5','2_12_6','2_13_3',
'2_13_4','2_14_3','2_14_4','2_15_4','3_8_3','4_12_3','4_12_4','4_15_3']
alphabet = """ABCDEFGHIJKLMNPQRSTUVWXYabcdefghijklmnopqrstuvwxy1234567890!@%^&*()_-+={}[]:;"'|\<,>.?/~`ABCDEFGHIJKLMNPQRSTUVWXYabcdefghijklmnopqrstuvwxy1234567890!@%^&*()_-+={}[]:;"'|\<,>.?/~`"""
translationdict = {motif: alphabet[a] for a,motif in enumerate(motiflist)} # dictionary of motifs and the corresponding string element
translationreverse = {translationdict[m]: m for m in motiflist}

orthocombos = [] #list where combinations of matching orthologs will be stored
conservation = {} #dictionary where lists of conservation per side are stored per motif
for m in motiflist:
	mlen = sum([int(mi) for mi in m.split('_')]) + plink + alink + 5
	mli = [0 for n in range(mlen)] #a 0 for each site, and finally a 0 that will count how many times this motif was found conserved
	conservation[m] = mli



'''
Prep libraries from existing result files
'''
#dictionary with the motifstructure of each gene
mseq_fa = open("%s/%s" %(dbfolder,motifseq))
mseq_dx = {}
seq_value = ''
for line in mseq_fa:
	if line[0] == ">":
		try:
			mseq_dx[key] = seq_value
			seq_value = ''
		except NameError:
			pass
		key = line[1:].strip()
	else:
		seq_value += line.strip()
mseq_dx[key] = seq_value

#dictionary with the aminoacid sequence of each motif hit
mhit_fa = open("%s/%s" %(dbfolder,motifaaseq))
mhit_dx = {}
seq_value = ''
for line in mhit_fa:
	if line[0] == ">":
		try:
			mhit_dx[key] = seq_value
			seq_value = ''
		except NameError:
			pass
		key = line[1:].strip()
	else:
		seq_value += line.strip()
mhit_dx[key] = seq_value

#random list of motifs for frequency-dependent selection of motifs
allmotxt = open("%s/%s" %(dbfolder,allmotifs))
allmotli = []
for m in allmotxt:
	allmotli.append(m.strip())
backupmotli = list(allmotli) #in case the list needs to be generated again. To prevent backupmotli from undergoing the same modifications as allmotli, it's imported as a new list entirely.
random.shuffle(allmotli)

def orthos(gene,k,ol):
	'''
	Look up per gene what their ortholog is. NB this may be multiple, as the gene could have multiple isoforms.
	'''
	isoforms = [ol[0][i] for i,j in enumerate(ol[k]) if j == gene]
	return isoforms #list of all isoforms
 
def clusters(genes,cdict): #genes is a list
	'''
	Look up the cluster they are assigned (both the Dmel and the Spp gene)
	'''
	clusters = [cdict[g.split('|')[2]] for g in genes]
	return clusters #list of clusters, same order as genes


def simple_wordcomp(i,j):
	'''
	Calculate pairwise distances for all the strings collected. As strings
	are regular expressions, first expand the re. and then calculate all distances
	pairwise. Return the minimal distance (with and without spaces).
	'''
	# translate strings[i] and strings[j] to all possible expressions
	sisplit = [part.split('|') for part in re.split(r'\{(.*?)\}',i)]
	sjsplit = [part.split('|') for part in re.split(r'\{(.*?)\}',j)]
	si,sj = [],[]
	for x in itertools.product(*sisplit):
		si.append(''.join(x))
	for x in itertools.product(*sjsplit):
		sj.append(''.join(x))
	# check jld of all strings[i] options against all strings[j] options
	distance = []
	for sin in si:
		for sjn in sj:
			distance.append(jld(sin,sjn))
	# return the minimum distance
	return min(distance)

def complex_wordcomp(i,j):
	'''
	Calculate pairwise distances for all the strings collected. As strings
	are regular expressions, first expand the re. and then calculate all distances
	pairwise. Return the minimal distance (with and without spaces).
	Additionally: find out which domain classes 'replace' each other in orthologs.
	Save these results in global lists.
	'''
	global m2m
	global letters
	# translate strings[i] and strings[j] to all possible expressions
	sisplit = [part.split('|') for part in re.split(r'\{(.*?)\}',i)]
	sjsplit = [part.split('|') for part in re.split(r'\{(.*?)\}',j)]
	si,sj = [],[]
	for x in itertools.product(*sisplit):
		si.append(''.join(x))
	for x in itertools.product(*sjsplit):
		sj.append(''.join(x))
	# check jld of all strings[i] options against all strings[j] options
	distance,distance2,sequencecomp = [],[],[]
	for sin in si:
		for sjn in sj:
			distance.append(jld(sin,sjn))
			#remove Zs and do it again
			sin = sin.replace('Z','')
			sjn = sjn.replace('Z','')
			distance2.append(jld(sin,sjn))
			sequencecomp.append("%s,%s" %(sin,sjn))
	# if there are differences: which motif turned into which?
	if min(distance2) > 0: #use the sequences without space/Z
		for k,d in enumerate(distance2):
			if d == min(distance2):
				#distance2 and sequencecomp have the same order, so sequencecomp[k] has sequences corresponding to distance = d
				comps = sequencecomp[k].split(',')
				sik,sjk = comps[0],comps[1]
				if len(sik) == len(sjk):
					for ki,si in enumerate(sik):
						letters.append(sjk[ki])
						letters.append(si)
						if si != sjk[ki]:
							fs = frozenset([si,sjk[ki]])
							m2m.append(fs)
					seqcomp.write("%s,%s\n" %(sik,sjk))
	# return the minimum distance
	return min(distance),min(distance2)

def calcdistance(gene,corths,ranseq):
	'''
	Calculate the minimum distance between the gene and its orthologs
	where distances are calculated between strings that summarize protein
	architecture.
	'''
	dists,dists_ran = [],[]
	seq_g = mseq_dx[gene]
	for co in corths:
		seq_c = mseq_dx[co]
		dist = simple_wordcomp(seq_g,seq_c)
		dist_r = simple_wordcomp(ranseq,seq_c)
		dists.append(dist)
		dists_ran.append(dist_r)
	return min(dists),min(dists_ran)

def randomorth(gene):
	'''
	Generate a random motif sequence based on identical ZF structure
	(including conservation of spacing) but with random frequency-dependent
	sampling of motifs.
	'''
	global allmotli
	regex = ['{', '|'] #components of regular expressions, to be excluded
	# NB } is not used because it indicates the re itself, and thus needs to be substituted by an element, too
	rehit = 0
	seq_g = mseq_dx[gene]
	ranseq = ""
	for l in seq_g:
		if l == 'Z':
			ranseq += 'Z'
		elif l in regex: #regex component followed by a motif
			rehit = 1
		elif rehit == 1: #catches the motif following the regex indicator
			rehit = 0
		else:
			try:
				ranseq += allmotli.pop(0) #remove the first element from the list and use it in a random seq
			except IndexError: #list is empty, so refill it.
				allmotli = list(backupmotli)
				random.shuffle(allmotli)
				ranseq += allmotli.pop(0)
	return ranseq

def list_re(seq):
	'''
	Removes spaces ('Z') and returns the sequence in list
	format for easy comparison, pooling regex elements.
	'''
	seq = seq.replace('Z','')
	seqli = []
	flag = 0 # used to mark regular expression
	regex = ''
	for s in seq:
		if s == '{':
			regex += s
			flag = 1
		elif s == '}':
			regex += s
			seqli.append(regex)
			regex = ''
			flag = 0
		elif flag == 1:
			regex += s
		else:
			seqli.append(s)
	return seqli

'''
Process the data in each ortholog comparison file.
'''
for orthfile in orthologli:
	try:
		of = csv.reader(open(orthfile))
	except IOError:
		continue
	ol1 = [line for line in of] # list from the file
	ol2 = [[x[i] for x in ol1] for i in range(len(ol1[0]))] # transpose the list
	### for each combination of species,
	sp1 = ol2[0][0] #the first column (now row) contains the comparison species
	for n in range(1,len(ol2)): #for each species comparison
		sp2 = ol2[n][0]
		print "Comparing orthologs between " + sp1 + " and " + sp2 + "..."
		#make a list of all the unique orthologs per species
		allorth = list(set(ol2[n][1:]))
		allorth.remove('')
		orthototal = len(allorth) #total no. of orthologs for this species combination
		dists,dists_ran = [],[]
		#collect the data
		for gene in allorth:
			corths = orthos(gene,n,ol2) #collect all sp1 isoforms that are mentioned as orthologs for this gene
			orthocombos.append([gene,corths])
			ranseq = randomorth(gene)
			di,di_r = calcdistance(gene,corths,ranseq)
			dists.append(di)
			dists_ran.append(di_r)
		#calculate mean, stdev, no. identical orthologs; respectively (for data and random model)
		arrdi = np.array(dists) #make array for numpy analysis...
		arrdi_ran = np.array(dists_ran)
		amean = np.mean(arrdi)
		amean_r = np.mean(arrdi_ran)
		astdv = np.std(arrdi)
		astdv_r = np.std(arrdi_ran)
		#following commented out, but can be used to find the mode/most common distance
		'''
		data = Counter(dists)
		dmode = data.most_common(1)
		data_ran = Counter(dists_ran)
		dmode_r = data_ran.most_common(1)
		'''
		# identical orthologs, so distance = 0:
		idcount = dists.count(0)
		idcount_r = dists_ran.count(0)
		ressum.write('%s,%s,%s,%s,%s,%s,%s,%s,%s\n' %(sp1,sp2,amean,astdv,amean_r,astdv_r,orthototal,idcount,idcount_r))
ressum.close()


## for each item in the ortholog-combo list:
for pair in orthocombos:
	# pick up the motif structure
	seqli_g = list_re(mseq_dx[pair[0]]) #make a list of the elements in this sequence, no spaces
	for o in pair[1]:
		seqli_o = list_re(mseq_dx[o])
		if len(seqli_o) == len(seqli_g):
			
			

### remove Z
### if they are the same length:
#### for each letter (or REs):
##### if they are the same:
###### pick up sequence for both
###### compare sequence, and do +1 for each different AA in the corresponding index of the motif's reference list
##### if they are NOT the same:
###### +1 in the array




"""


#Read cluster file and make dictionary
cf = csv.reader(open("%s/%s" %(dbfolder,clusterfile)))
cdict,sdict = {},{}
for line in cf:
	name = line[2]
	cdict[name] = line[3]
	sdict[name] = line[4]

#Header line of results file
ressum.write("Species,Orthologs,Orth in same cluster,percentage,Identical orth,percentage,Levenshtein total,Levenshtein average,Identical orth (no space),Levenshtein total (no space),Levenshtein average (no space)\n")

for k in range(1,len(ol2)):
	#make a list of all the unique orthologs per species
	allorth = list(set(ol2[k][1:]))
	allorth.remove('')
	print 'species:', ol2[k][0]
	print 'total no. detected orthologs:', len(allorth)
	clcount,idcount,idcountnoZ = 0,0,0
	dists,distsnoZ = [],[]
	for gene in allorth:
		dmorths = orthos(gene,k,ol2) #collect all Dmel isoforms that are mentioned as orthologs for this gene
		gene = [gene] #the clusters function requires a list input
		cl_gene = clusters(gene,cdict)
		cl_orth = clusters(dmorths,cdict)
		if cl_gene[0] in cl_orth: #If one of the isoforms has the same cluster hit as the spp ortholog, score as 1
			clcount += 1
		#calculate the minimum distance between this gene and the dmel ortholog(s)
		dist,distnoZ = distance(gene,dmorths,sdict)
		dists.append(dist)
		distsnoZ.append(distnoZ)
		if dist == 0: # if the domain structures are identical, score as 1
			idcount += 1
		if distnoZ == 0:
			idcountnoZ += 1
	print 'total no. orthologs in same cluster:', clcount
	print 'percentage of orthologs in same cluster:', clcount/float(len(allorth)) * 100
	print 'number of identical orthologs:', idcount
	print 'percentage of identical orthologs:', idcount/float(len(allorth)) * 100
	print 'total levenshtein distance:', sum(dists)
	print 'average distance:', sum(dists)/float(len(dists))
	print 'number of identical orthologs (without space):', idcountnoZ
	print 'total levenshtein distance (without space):', sum(distsnoZ)
	print 'average distance (without space):', sum(distsnoZ)/float(len(distsnoZ))
	print '\n'
	ressum.write("%s,%s,%s,%s,%s,%s,%s,%s,%s,%s,%s\n" %(ol2[k][0],len(allorth),clcount,clcount/float(len(allorth)),idcount,idcount/float(len(allorth)),sum(dists),sum(dists)/float(len(dists)),idcountnoZ,sum(distsnoZ),sum(distsnoZ)/float(len(distsnoZ))))

seqcomp.close()
ressum.close()

'''
Part II:
Which domain classes are parallel in non-identical orthologs?
Make a heatmap of this data.
'''
combocount = Counter(m2m) #dictionary with frozenset-motifcombinations, and their frequency
letterscount = Counter(letters) #dictionary with individual letters, and their frequency

#collect data for the heatmap in a 2d list
table = []
for m1 in motiflist:
	l1 = translationdict[m1] #corresponding string element of main motif
	total = letterscount[l1] #total frequency of this motif in the dataset
	row = [] #empty row that will collect relative frequency data
	for m2 in motiflist:
		l2 = translationdict[m2] #corresponding string element of comparing motif
		fs = frozenset([l1,l2]) #combined frozenset of main and comparing motif
		if fs in combocount: #if this combination is found:
			freq = float(combocount[fs]) #give total frequency of combination (float to enable float result)
		else:
			freq = 0
		row.append(freq/total)
	table.append(row)


###HEATMAP###
data = pl.array(table)
colourformap = "YlOrBr"
fig,ax = pl.subplots()
heatmap = pl.pcolor(data, cmap=colourformap)
cbar = pl.colorbar(heatmap)
	
# put the major ticks at the middle of each cell
ax.set_xticks(np.arange(data.shape[1]) + 0.5, minor=False)
ax.set_yticks(np.arange(data.shape[0]) + 0.5, minor=False)
pl.axis('tight') #remove the white bar
ax.invert_yaxis() #make sure it starts counting from the top
	
#make the labels
ax.set_xticklabels(motiflist, minor=False, rotation=90)
ax.set_yticklabels(motiflist, minor=False)
	
# save the figure
pl.savefig("%s/%s" %(dbfolder,hmimage), dpi = 300)

'''
PART III: sequence comparisons of conserved motifs
'''

"""
